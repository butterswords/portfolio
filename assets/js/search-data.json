{
  
    
        "post0": {
            "title": "CRAFT 61: Big Data and AI in the Global South",
            "content": "I took notes for myself during the CRAFT session on June 21st and have since realized that these may be more useful if shared broadly. Any mistakes are my own. I have removed contact information from here because I do not intend to share it without their permission. I’m sharing their names and their work because it is present on the website for the workshop. . High Level Thoughts . I was honored to be able to listen, learn, and engage with the keynote speakers and presenters. They brought forth excellent and diverse points. As one of a few white people who attended the CRAFT session I have to acknowledge two things: . the timing of the event reinforces entrenched, asymmetrical power dynamics | as a white man who works for a tech company, I am closer to the center of power than the presenters are–even as I feel powerless to affect change on any given day | . The event was at a convenient time for me (12:30pm to 4pm PDT). It was inconvenient, even unreasonable, for almost all other attendees and the presenters who had to be up in the middle of the night for hours to participate. I am disappointed in the timing of this event and have voiced my concerns to the conference. I hope future conferences learn from this and find timing that is more convenient for the speakers. The irony is not lost on me that this session enacted the very power asymmetry it was critiquing. . The second point is something I am struggling to put into words more clearly. I exist on the periphery of power within every organization I belong to. I consistently advocate for others who are excluded to have a voice and challenge dominant power structures. This tends to make me seem like a threat to my managers and executives because I am not okay with just doing the work to make the company money. I believe I have to do it in a way that promotes human flourishing. . Reflecting on everything that was said during the workshop and the issues at play with internet quality, timing, etc. I realized how I may (or “must”, I’m unsure about this) come across to others. It was truly humbling and reinforces how much I consider myself peripheral to the work of bringing diverse, under appreciated voices towards the center. . The critical themes I’m taking from the workshop: . The social construction, and usage, of data demands that we refrain from the impulse to universalize and focus on relational meaning | Theory and practice both need to originate from the Global South to be truly beneficial to those communities | Inequality, power asymmetry, and colonization are likely to grow with greater adoption of AI until we can achieve the first two points | My own addition: I believe the field of AI needs to draw from the depth of thought in the humanities, acknowledging that they are also centered in the Global North, to avoid recreating the wheel and further eroding language with more jargon or siloing | Keynotes . Dr. Nimmi Rangaswamy . She gave a talk on centering human and cultural experience in our discussions of AI. She focused on some key points that I’ll list below. Sadly, her talk started a bit earlier than the scheduled time so I missed a portion. . Dr. Ragaswamy discussed: . Legacy Systems | Problems of data needing to be based in context | Offshoring AI | Inclusive AI | . My key takeaway . We need to view data as socially constructed rather than as “being real” in itself. To me this means we need to challenge the concept of most conceptions of “ground truth,” because people often fail to critically reflect on what that means. They tend to generalize from the “ground truth” as if it represents some universal form of truth. . Dr. Nick Couldry . He gave a talk largely centered in his book, The Costs of Connection, and he talked about how we as practitioners need to recognize that data is a continuation of the colonial enterprise. It is not something new, or “capitalism gone wrong”, but rather it is an extension of hundreds of years of history using a new tool for control. . He directly argues against Shoshana Zuboff’s book, The Age of Surveillance Capitalism, considering his work to go beyond what she offers. I do not agree with his critiques on the surface (having recently read her work and not yet gotten to read his). I am going to capture a few points here and expand on them after I’ve read both works. . Against Surveillance Capitalism He feels Zuboff’s work agrees with a lot of the points of Data Colonialism but doesn’t theorize colonialism on any level | He points out that his work addresses two critical things not covered: Scope - time and sheer scale of what’s going on | Depth - Forces us to think about how colonialism changed the world | . | . | Other works recommended: “Your Privacy is Important to Us! Restoring Human Dignity in Data-Driven Marketing” Jan Trzaskowski | . | . My Key Takeaway . I think I fundamentally disagree with Couldry’s critiques of Surveillance Capitalism. I do think that his work adds another layer to what she’s exploring. Both appear to offer deep insight into how data exists in the world and I think they may be more complementary rather than exclusive. Couldry’s perspective appears to look at it from a historical perspective, while I would say Zuboff is theorizing a new type of power (e.g. Instrumentarian Power) that the tech companies and governments are using to shape reality. . Presenters and Organizers . Deepa Singh . Her talk was about reimagining AI Ethics in India. She talked about focusing on situated ethics (within cultures and contexts) to ensure we’re not trying to create false universals. Her focus was on breaking away from binary distinctions because “our ethical and moral actions happen in a particular context” and what we see as ethical may change based on who we are, where we are, or what is happening around us. . Other key things she mentioned: . Ontological Shift Knowledge attuned to resonance (rather than a universal truth) | . | Rationality as a false universal What is a rational account of the world? | Whose ideas and values are you carrying forward? | . | Construction and upholding of these values are inherently acts of power Centers of Hegemonic Power - Global North | . | . My Key Takeaway . As an existentialist I find that Deepa’s perspective resonates with what I differentiate as “T” Truth and “t” truth, which focuses on how we exist and what we can know. Her words provided a powerful reason to push us towards a less externalized understanding of truth–there is no “objective” truth–and towards relational truth. How are we present in relationship with others? How do the ideas we carry become embedded in AI systems? . Rokeya Akter . Rokeya presented on building an OCR model for text extraction from images within the specific context of Bangladesh. They discussed the challenges they faced, which represented a good insight into the technical hurdles of working in data-scarce environments. . Some challenges . There’s no data in a Bangladeshi context She described her method for the collection of the images | The difficulty of finding ones with the date pattern on the image | . | There does not appear to be crowdsourcing for images in Bangladesh Someone asked: Are there platforms that allow you to find the images you need? | . | . My Key Takeaway . I had two takeaways from this. The first was how technical literacy/familiarity and internet access create enormous disparities in how data science can be done in specific contexts. The second was, unrelated to the talk, about how these developing countries still have time to create laws to protect the biometrics of their citizens while more developed ones that have weak laws may be too late. . Chinasa T. Okolo . Chinasa wrote a survey of explainable AI (XAI) in the Global South for the conference. You can find her paper here. She discussed a lot of the issues with how AI is being brought to and used in the context of the Global South. . Little work has been done to assess workers’ understanding of AI They are novices in how it works and what it can do | Due to this it can exacerbate the inequalities, issues, and workload in these communities | . | Chinasa’s ideas for the future: Centers Humans - acknowledging constraints | Engaging with communities - fieldwork and ethnography | Converging on a Research Agenda - to address and resolve inequities | . | . The audience had some great questions (Note: I’ve removed who asked questions because I don’t want to make their information public without their permission.) . One attendee asked about the tension in balancing the organizational and resource constraints with the need to engage communities. . Only 1 intervention actually used XAI in the field of the 16 papers assessed | 3/16 are planning on deploying in the field | . Another attendee asked whether there are good models in technology prior to AI that are potentially useful for Chinasa’s work. . All the papers are within 2019 to 2021. Looking into other tech deployments (earlier) may be very useful. | . | Ex. Google AI and Google Health - pushed AI to address Diabetes in Thailand Highlighted several problems on the ground, such as insufficient lighting | . | . My Key Takeaway . Chinasa’s paper represents an excellent opportunity to reflect on how XAI is being used in the Global South by people who may not be aware of or intentional about the needs of those in the context they are working. It seems like a great starting point for having a conversation about what it means to “bring AI to underserved people” and how researchers need to consider how their work capitalizes, reinforces, or creates inequities. . Aprajita Bhandari . From Cell Phones to Crisis Mapping: Datafication of Humanitarian Aid as Enactments of Neo-Colonial Power . She discussed her work researching how data can be used during and after disasters to create surveillance of citizens and then export that data for the benefit of others. The context was an earthquake in Nepal in 2015, where thousands of people died. A non-profit (flowminder.org) partnered with the service provider (Ncell) to do a data collaboration. They shared the data with the UN in the name of aiding those affected by the earthquake. . Questions she asks . What liberties are eroded in times of crisis? | Who makes these decisions? | Who is impacted? | . She grounds her work in Post-Colonial Theorists . Manidou - Techno-Colonialism | Glissant - Right to Opacity | Fanon - Occupied Breathing | . She’s currently examining new projects with Flowminder. . How is data-driven humanitarianism proliferating across the globe? | These require surveillance technology to work | Reinforce top-down solutions | . Her goal . It is not to provide blanket criticism | Capture the complexities of data collection and how they become embedded in larger colonial systems | . A few of the questions from the group . Have you thought about or read research on futuring and speculative futures? What are the potential positive paths forward? | . | With crisis there’s an interesting dynamic, the people who are thinking about a potential crisis are likely not the population? How would you even think about bringing power back to the people? | . | . My Key Takeaway . Aprajita’s work highlights the criticality of protecting decision rights for individuals and communities. When other “interested” parties get involved without engaging the communities throughout the process there will always be issues of power and authority. One of the biggest things I felt upon listening to her work was how reactive all of these implementations of AI are and therefore how critical it is to have protections in place ahead of disasters. It reinforces the need to drive policy to protect people proactively. . In Washington state there is a very real fear of a major earthquake in the next 5-15 years, if that event occurs it could destroy large parts of Seattle and the coastal residences around the Puget Sound. Washington has failed to pass consumer privacy acts that would protect people’s personal information. In a situation like the one Aprajita describes, “well intentioned” organizations could co-opt “aid” to gather a tremendous amount of personal data. . Questions I have: . Are residents of WA more vulnerable due to their proximity to Tech companies like Amazon, Microsoft, Google, AT&amp;T, T-Mobile, Verizon, and the like? | Are they more vulnerable due to the number of devices they have connected to the internet? | Can we use this situation as a thought experiment to alter the focus, asking the question “how would we want this to be used on us?” Would we then be able to bring a new perspective to working with communities in the Global South that becomes more of a dialogue and less of an imposition? | . Abdullah Hasan Safir . Digital Divide Using Data Science Techniques . Abdullah explored internet access using visualization methods to highlight some aspects of how data visualization may reinforce the inequalities in the data. He applied K-means clustering using 213 countries of the world into three clusters. His argument was that visualizations and analytical techniques can recreate inequalities. . Data . GapMinder from UN (ITU) | Lots of missing data in the dataset Used nearby available data (most recent year of available data) | . | Requires manual adjustment of country names Data Rich vs Data Poor regions (lots of issues in Africa and 0 in Europe) | . | . Visualizations . Dot Plot by Continent | Choropleth of the World Map | Line Graph showing trend of continents by year over 29 years Ignores specific countries and context | . | K-Means Clustering in a simple Table of 3 columns Applied a cluster against the world average | Then show the clusters on the world map | . | . My Key Takeaway . Data visualization is both an art and a science. Some of the points made about visual analysis are well known in the field, and require individual creators to make choices that best fit their data, audience, and intentions. One of the others, specifically the choropleth of the world map, reiterated some things I’ve struggled with: . Who determines what countries are recognized, and how they are labeled, within products? | Since most are created in the Global North, there is a fundamental imposition of values and worldviews that propagate any time we use these technologies. Does your map recognize Congo as two nations? If so, what names does it use? | . | For other countries with complex colonial histories, what name is used and does it match the way the people who live there refer to themselves? | . Mohammad Rashidujjaman Rifat . He explored what it was like working with religious communities around technology and AI. He brought up two case studies: 2017 in Bangladesh and 2020 (I didn’t capture where). I have captured some of his statements and quotes of participants to the best of my ability. Consider any quotes to be highly suspect unless you verify them directly with him. . Case 1 . 2017 - work trying to understand how mosques are using technology and their attitudes in Bangladesh | 1 person said television is a “box of satan”. paraphrase ‘The larger trend is that there are ethical concerns around letting children see television programs’ | . | 1 person said “social media will destroy their children”. paraphrase ‘Moral opinion is that they should not let their kids interact with people who are from different perspectives’ | . | . Case 2 . 2020 - an ethnography of people recording Islamic public preaching and uploading them | Focused on Facebook &amp; TikTok Someone said they don’t watch videos on YouTube. Their reasoning is that there are a lot of videos on islamic on YouTube but he doesn’t want the commercial interference from unexpected ads in the middle of his video Auto play leads to other types of content are brought into his view unexpectedly | . | . | Others don’t use AI because they “predict” the future Only God can predict the future | . | . Questions . What are the assumptions people bring into their views or uncertainties about using technology? | How do people manage the uncertainties they have around these technologies? | How does this connect to the ideas of justice and fairness in AI? | . My Key Takeaway . Religion and technology are two things I’m fairly familiar with. When listening to Mohammad speak I kept focusing on the ideas of insider and outsider (aka. emic and etic), as it exists in linguistics and sociology. Who holds the truth in these situations is a fundamental question for qualitative research that continues to be debated in these fields. . For the work of justice and fairness in AI, as posed in the last question, I find that it relates back to what Dr. Rangaswamy mentioned at the end of her keynote on understanding all data as socially created. To find solutions for communities such as the ones described within Mohammad’s case studies one must ask whether to privilege the views of the community or the observer. . One must negotiate the needs of all parties involved to identify something that is both practical and minimizes harm. This is something I aim to explore more. . Sharifa Sultana . Big Data, AI, and Misinformation in the Global South . Sharifa discussed some ethnographic techniques to work with people in Bangladesh. They studied fact checking and social effects in rural Bangladesh villagers in the Covid-19 pandemic and what is or is not “misinformation”. An example of misinformation was someone “selling amulets on the street claiming they could cure Covid-19”. It is hard to check facts because in Bangladesh only 3 entities are authorized for fact-checking. Very few people engage with them; it is mostly news agencies. Therefore, rural villagers rely on social experts’ opinions to create their understanding and gauge veracity. . Since these are not categorized as “rational” how do AI systems account for these? | How can we make these systems more tolerant of alternate ways of seeing the world? | . Questions . Is misinformation associated with radical groups in Bangladesh (such as the far-right in the US)? She has a hunch that they might be but did not actually examine this directly | . | Can we suggest a different train of thought, rather than “non-rational” is not included? What if we consider “rational first” is embedded in the data systems? (Changes the question to a bit more positive framing.) Because of the way data and comp sci is taught the local person may not code their understanding into the system. | . | . My Key Takeaway . Much of what Sharifa said resonated with Mohammad’s observations and Dr. Rangaswamy’s perspective. By forcing the Global North’s universals onto communities and populations they are inherently subverting the decision rights and autonomy of those groups. We as researchers, global citizens, and technologists need to understand this and find ways to ask how we can build systems that support other perspectives by default and allow us to achieve our ends without imposing our worldview as the “definitive” truth or some idealization of rationality. . Yousif Hassan . What does it mean to decolonize AI ethics? . Focuses on development of AI in the African context. He points out that AI Guidelines are being developed by largely western nations (‘just restating the obvious to make sure we’re all on the same page’). Then the Global South attempts to adopt these frameworks (embedded western epistemologies). . His overarching questions . How should researchers and policy makers approach AI governance in Africa? AI4D (AI for Development) - ACTS in Kenya, Ghana AI Ethics Lab | AfriLabs in Nigeria | . | . Main Argument . Researchers lack the African Context | Decolonization is put forward as the “solution”, which he refutes as being truly useful He argues these economies purposefully exclude the imaginations of marginalized communities | . | 3 main points Seems to only broaden the critique of AI | Doesn’t problematize the historical origins of ethics and intelligence | Doesn’t center the future in the African Context | . | His way forward Move the project of theory making to the south | Examine new conceptions of blackness under regimes of techno-scientific capitalism | Engage with processes of co production in the margins | . | . Questions . How do you collect your data? Semi-structured interviews (40) with people in Canada, Kenya, Ghana, and Nigeria | . | Are you familiar with Tyson Yunkaporta’s book on Sand Talk? It’s not a rejection of Western philosophy but the need to bring it into conversations with local contexts | . | Are we exporting Canadian values and projects to the local context that may not be appropriate? Is it a form of neo-colonialism? One of the things that was looked at is the asymmetries of power, they approve the projects and success criteria for them | . | . My Key Takeaway . I appreciated Yousif’s call to “move the project of theory making to the south” as I think there is a great deal of knowledge that is trapped at the periphery, or excluded entirely, because it doesn’t fit dominant narratives. When I heard his talk I was immediately reminded of the Stanford HAI’s recent talk with Sabelo Sethu Mhlambi, The Movement to Decolonize AI: Centering Dignity Over Dependency. I believe that the idea of “decolonializing AI” takes more than just changing the focus or allowing communities to participate. I feel it requires us to approach communities in a new way. . I’m also reminded of Tyson Yunkaporta’s book, Sand Talk, because it discusses a way of approaching people that keeps them in focus the entire time. In short it’s a methodology of approaching a community using a framework of Respect –&gt; Connect –&gt; Reflect –&gt; Direct. . Respect first by acknowledging, accepting, and supporting their autonomy and way of thinking. | Connect with the community, and its individual members. The focus must be on what they need, want, and can sustain. | Reflect on what, if anything, you have to offer them and whether or not they want you to be a part of a “solution”. | Direct the creation of any solution alongside the community in an act of partnership and mutual interest. |",
            "url": "https://butterswords.github.io/portfolio/facct%202022/conference/reflections/2022/07/05/craft61-big-data-ai-global-south-notes.html",
            "relUrl": "/facct%202022/conference/reflections/2022/07/05/craft61-big-data-ai-global-south-notes.html",
            "date": " • Jul 5, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Understanding the history of our brewing collective",
            "content": "This is a test post to see if I can make embedding vizzes work on this site. . What’s happening here? . . Trying a different way .",
            "url": "https://butterswords.github.io/portfolio/test",
            "relUrl": "/test",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Picking a robot to teach my son to code",
            "content": "From the moment I knew we were going to have a kid, before we knew the gender, I’ve been thinking of ways to get them to engage with robots. I love robots. I want to share that love with those around me. This is not a new thing for me. Years ago I bought a Wonder Workshop Dash robot for my nephew. He didn’t get into it. It was likely not something him and his father wanted to invest the time in to figure out. I realize I gave them a gift that I would want more than something I knew they’d enjoy. Still, it looked like an amazing idea and one I have been carrying around as an idea for my own kids. I have watched that toy for years, looking to see if they made a version compatible with a younger age group. They have not. So, when my son was born I started looking for newer robots and wondered if I could justify getting one for him. . Watching my son explore Duplo on the floor at 2 years old made it clear how much he enjoys putting things together. I spent hours with him, building things and seeing what he’d do with them. He would puzzle over things I’d built. Take them apart. Try to put them back together. Get frustrated. After a while he would put something completely different back together. It surprised me that at 2 and a half he understood the anatomy of planes and automobiles. He’d show me a “plane” he’d built. He’d use two long pieces, often at odd angles for wings. He even included one at the back for a tail. I couldn’t believe he had put them together on his own. It made me proud. It made me want to push him. It made me wonder at what age I could give him a robot. . This post is a place for me to share my thoughts on it for anyone it may help. It is not a review of different robots. I am not an early childhood expert, so take my words as those of a father who spent dozens of hours looking at the options. . Should you teach your kids to code? . Short answer: I think you should expose them to it. I don’t think you should force it on them. . The reasons I have for doing it . The ability to code is in high demand in today’s society. There is a shortage of programmers. The situation will only going to get worse as the need continues to outpace the system’s ability to provide adequate guidance. As technology develops at a rapid pace, I foresee two types of people emerging. There will be the general populace. They will be users of systems, who do not ask how the systems work. Then there will be those who understand how to interrogate systems. The power will likely rest with the latter, so coding will only grow in importance in future generations. Kids who grow up knowing how to code will always have an employable skill. . If done right, coding can teach fundamental skills for the developing mind. Some of the ones I’ve seen: . cause and effect | problem solving | creativity | emotional control | math is fun | . It’s also a great way to bond with my son. Since he’s only 3 I do a lot of the work, and I get to ask him what he thinks we should do or where we should put the square. It’s an interactive process that reminds me how awesome it can be to learn new things. I love seeing him shout “victory”, with an unrepentant glee, when the robot makes it to the end of a run and achieves its goal. I love when he tells me he’s going to make it stop, or when he puts another square down and figures out some novel interaction. . Things that gave me pause . The thing I’m most worried about as a parent is projecting my interests on to my child. I believe programming is critical to the future, but that’s one perspective among many. I can’t pretend to know what the future will hold and I don’t want to try to make my son into a reflection of myself. It took me a while to accept that there’s a difference between exposing him to my interests and forcing them upon him. I will likely struggle with this throughout his life, so it’s good to learn early on where I stand with it. . Another significant concern I have is about expectations. The world imposes a lot of expectations on children and I feel social media is increasing those at an alarming rate. I don’t want to increase pressure on my son by making him think he has to perform at a certain level. I will do what I can to protect him from performance anxiety by making sure we focus on having fun more than anything else. He will learn no matter what, so it’s more critical that he enjoys his robot and decides how far he’s interested in going. . What makes a good system for teaching young kids (2-5) to code? . There are a few key things I was looking for when I researched different options for a robot to teach my son to code. Most of the things I’ve seen are for 5-15 years old and include direct interaction with coding elements, whether limited by software or hardware. I wanted to find something that felt like it would not be too far off where he’s at developmentally to be useful. I finally decided on the four things below: . It has to be screen-free as I don’t want him to constantly be on a phone or tablet | All major elements have to be accessible to him without my intervention | I wanted one that required no ability to read to get the full benefits of it | I hate buying something and then discarding it because it’s been outgrown | . I saw several good options, and learned about one or two more after I’d made my decision. For the moment I’ll refrain from saying what I went with until I am able to talk about the options I found. . What are the options out there? . There are tons of robots out there. Some are made by Fischer Price, some are made by tiny boutiques. The ones I list below are ones I found had a clear educational framework and were as much about the learning as the playing. They all also seemed to be geared towards schools and classrooms, which meant they likely had support for activities or a curriculum. As this is not a “review” I’m going to provide my description and a single pro and con for each. . Sphero Indi . . Sphero has many robots targeted at different age groups. The Indi seemed most geared towards the 3-5 age range. It is a little blue car with color sensors so that when it runs over a mat with a particular color (ex. red) it will take a particular action (ex. stop). It has an app associated with it that kids can use to drive it around, or change how the robot interacts with the colors. . Pro - the app allows it to evolve with the child and provide countless opportunities for creating novel interactions | Con - it only has one type of sensor so it only works with the cards provided (or a very specific color palette that’s hard to find) | . Cubetto . . A cute wooden robot that has a lot of character. It has a separate board to program the motions so that a child can learn they have the ability to affect things from a distance. It has mats that can be used to tell stories and provide more ways for kids to imagine how to interact. . Pro - completely screenless, even the more advanced code elements are done through different shaped pieces | Con - it did not seem capable of evolving with my son so much as they want to buy story packs as a way to increase replayability and creativity | . Cubelets . . Little blocks that attach to each other to create countless interactions. From the website: . Each Cubelet has a special function and belongs to one of three categories: SENSE Cubelets take in information from the robot’s environment. THINK Cubelets compute and change that information, and ACT Cubelets turn that information into physical action. . Pro - Extreme customizability and can interface with lego | Con - The supply chain made it impossible to buy a set | . Botley . . I heard about this one from a friend and former colleague. He got it for his daughter who’s a bit over a year older than my son. It seems like a great educational toy. It’s aimed at 5-9 year olds. It’s for kids a bit older than the others I was looking at and it seems to have a full remote for direct control of the robot. . Pro - it has arms and can be used with specific activities that the other robots do not support due to their design | Con - I don’t know enough about it to give it a con, so I guess that is the con | . Kibo . . This is the first robot I found after my son was born. I’ve been following them for years and it seems like they have an active community in the education space. It’s a completely screenless wooden robot with a lot of customizability. . Pro - you can add a lot of parts to it to make it do different things | Con - the different packs get pricey so it does not feel right for a personal purchase | . What I chose and why . I made my choice after much hemming and hawing. I kept going back and forth on price point, design, and each robots ability to scale with my son’s development. In the end, I decided to go with the Sphero Indi. . It has a solid design, small and lightweight while still being very sturdy. He can hold it in his hands with ease and move it from tile to tile. He has already launched it off the couch once or twice and it seems to take impact from 2-3 feet pretty well. I worried about him running it into things, because it makes an awful noise, but that has not yet caused any issues with its performance. . It has customizability through stickers and changing the color of the lights through the app. This has been a hoot for my son as he loves stickers. . The floor tiles are large and bright, making it easy for my son to interact with and differentiate between them. He loves saying, “Green means go, Red means stop, Yellow means caution!” It’s awesome to watch him explore them. I enjoy it even when he’s refusing to use them as they’re intended because I know he’s figuring his own way through it all. . It has challenge cards that, without any words, teach the mechanics of the robot. There’s also a free pdf that walks through the basics. It’s amazingly intuitive and I can’t wait to just let my kid see it and interact with it. I actually think it’s a perfect case study for teaching design principles to technical writers (but that’s a different post entirely). . Note: As a father I encourage anyone reading this to be more patient with their kids when they lose focus. It is critical to give them space to process when they stop trying to make things work. I admit it frustrates me, especially when it’s accompanied with faux plaintive screaming to try to manipulate me. I know it’s part of my son’s development and I have to control my reactions to ensure he has a great experience. . The cost was reasonable. Compared to some of the others I mention it ranges from $80-120, depending on if you get the school version or the home version. I went with the school version because I want the higher quality materials that will last longer. Even spending the extra money it’s a hundred dollars less than some of the other options. . Lastly, the app provides enough additional functionality that I know my son will be able to use this for years to come without outgrowing it. By that time I hope he’ll be ready to teach a younger sibling how to use it. . I’m excited to watch my son learn how to use his robot. I can’t wait to see him figure out some of the challenges and start using the app to customize how the robot works. I know that it’ll take years for him to master the robot and I am going to enjoy every moment. .",
            "url": "https://butterswords.github.io/portfolio/journey/robots/fatherhood/2022/01/23/picking-a-robot-to-teach-code.html",
            "relUrl": "/journey/robots/fatherhood/2022/01/23/picking-a-robot-to-teach-code.html",
            "date": " • Jan 23, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Reflections on my first Kaggle Collaboration",
            "content": "Transitioning from coursework to practical application is difficult. It’s one thing to take courses on Data Analysis for Social Science or Probability - The Science of Uncertainty and Data. They provide a solid foundation and theoretical framework to work with. It’s another to apply that and achieve results. I struggled a lot with finding ways to make use of what I’m learning because my previous jobs have been in SEO (Search Engine Optimization) and did not afford me the time or freedom to do it through my work. In November of 2021 I reached out to a friend of mine to see if he had any interest in exploring machine learning. To my great joy it turned out he did and we agreed to team up and try to do some Kaggle competitions together. . We decided to tackle the Natural Language Processing with Disaster Tweets as a good entry point into the world of Kaggle Competitions. The rest of this post describes our process and my personal learnings. . Note: I am focusing on NLP (Natural Language Processing) because there are many ways I can incorporate it into my work, which will only serve to reinforce everything I’m learning along the way. . Setting goals . I find a good place to start any project is with concrete goals and how to work together. It comes from years managing projects across organizations and clients where success depends on how well you understand the end state at the front. We took time in our first meeting to set the groundwork, below are the list of the goals we came up with. . The goals of our first project: . Test Kaggle Notebooks to see how they work and the odd nuances that come with a specific product | Classify tweets as 1 (pertaining to a disaster) or 0 (not pertaining to a disaster) | Get comfortable working as a team | Get a better sense of using NLP for text classification | . Developing a process that works for collaborating . While we had explicit goals, we did not have any process for achieving them. We’re two friends after all and so we just decided to wing it. That worked surprisingly well, all things considered. I did a lot of research and exploration and then we worked together to refine things as we ran into problems. . Merging teams and then code . Kaggle has some really excellent tools that you get access to for free. Each person having the ability to work in a notebook with access to GPUs is excellent. We initially started our work separately, and then about two weeks into the process we decided to merge our work and create a team. The creating a team part was simple and seamless. The merging of code was completely manual. I can’t blame Kaggle for that, they give you a bunch of stuff for free. It’s just one of those aspects of the learning curve that I feel is unavoidable. If I were to do it again I would say: . Do not start your project in separate notebooks on Kaggle unless you plan to merge very early | Make sure the person who has more detailed code becomes team lead | Copy your notebook locally before merging teams so that you can merge code later with ease | . Once the team was formed we had to figure out how we were going to do all of our future development. This lead to some interesting discoveries about versioning on Kaggle. . Developing in Github vs Kaggle . Once we had built a team we both tried to go into the notebook and start to work synchronously. First, there’s no functionality to allow for simultaneous editing (not a big deal as it’s all free) and no concept of branches or pull requests that I could find. This became much more problematic as we realized that Kaggle doesn’t always default you to the last edited version, but rather the last version you touched. When you want to go to an updated version you have to “revert” to it, which doesn’t really make sense if you’re on v8 and the latest is v14. This through me for a loop more than once. . A saving grace, at least for me, was that Kaggle allows you to import notebooks directly from Github. That allowed me to download the latest version and then work locally (like a branch native to Github) and then I would pull from Github when I was ready to push it back into the Kaggle environment. The functionality for that is very basic, however, which made for some interesting renaming of repositories. . . There’s a quickselect for Github, which is nice. | The search functionality is powerful, but flawed. There should be an option to select only from private repositories connected to your account, not just an inclusion of those in your search results. | The upload is nearly instantaneous depending on size of the file and your internet speed | It was much easier for me to develop in Github than directly in Kaggle because I could use my Jupyter Lab settings and keep files locally. One caveat, you have to maintain a line of code for loading data in each cell that allows you to switch between environments. I would likely consider adding a helper class for much larger projects that detects the environment and automatically updates the path for reading files. Though manually switching, see below, isn’t too problematic if you have limited inputs. . &#39;&#39;&#39;In this scenario I am editing my notebook on my local machine. So I have commented out the kaggle-specific pathing.&#39;&#39;&#39; #sample = pd.read_csv(&quot;/kaggle/input/nlp-getting-started/sample_submission.csv&quot;) sample = pd.read_csv(&quot;sample_submission.csv&quot;) # For Local machine . At the end of the day, I think it makes a lot more sense to develop non-GPU code in Github. You can then import the notebook into Kaggle to train the models. . note: I have not tried this for GPU-specific projects, like deeplearning for NLP or Computer Vision yet. I may update this line based on my experience when I get there. . Developing different methodologies based on different tutorials . Developing asynchronously, we each took a different way to exploring approaches to the problem. We found different Kaggle Tutorials and that led to some very interesting early discoveries. We realized that there were so many ways to approach the problem that it made sense to test our work against each other and see if and how we could improve on one another’s work. . My friend used an NLP Getting Started Tutorial that is widely viewed and used (roughly 100K views and 2.3K copies). It achieves a base accuracy of around 78%. . I took the approach of incorporating some of the work I was doing through codecademy’s Data Science Career Path with SKLearn’s tutorial on NLP: Working With Text Data. This lead me down several deep rabbit holes, but was richly rewarding for a better understanding of creating pipelines with sklearn, more on that later. My final model achieved an accuracy of 82.08%, which is not an insignificant improvement over the original. Though admittedly it was more complicated and less efficient. . Below is a simple look at all the libraries we ended up including based on our work together. . #Import all major libraries we&#39;ll need to create and run our models import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split #Standard for building Training and Test sets in data from sklearn.preprocessing import StandardScaler # To process what we need from sklearn.model_selection import GridSearchCV #To optimize our model&#39;s parameters from sklearn.pipeline import make_pipeline #To make a pipeline for GridSearchCV from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #Two of our text processing pipelines from sklearn.svm import LinearSVC, SVC #Loading a Support Vector algorithm to classify the text from sklearn.linear_model import RidgeCV, LogisticRegression #for StackingRegressor from sklearn.naive_bayes import MultinomialNB #Loading a Bayesian algorithm to see if it&#39;s more accurate from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay #For Identifying the type of errors from sklearn.ensemble import StackingClassifier, RandomForestClassifier #for attempting to combine multiple models . Testing methodologies, comparing results, and choosing a model to submit . Because we took different approaches we wanted to formalize how we evaluated and compared our models to see what we were going to submit. This was mainly for ease of our communication as Kaggle allowed us to submit 5 times a day, and we could do it for as long as we like. We ended up using simple line of code recommended in the documentation and almost every tutorial to evaluate accuracy. . print(f&quot;Accuracy: {svc2.score(X_test, y_test) * 100:.3f}%&quot;) . It worked well to gauge between models on the test data. Where it was really informative was in showing us how the performance on test data compared to the competition data. I want to take a moment to note that I use test here because it is the language used in sklearn.model_selection.train_test_split and it is better to consider our test data the validation data based on my understanding from the FastAI course. . Key learnings from the experience . I learned a lot in tackling that first competition. Some of it was mundane (Ex. how to set up environments and move between them) while others were truly enlightening. The ones I will carry with me and want to share are outlined below. . Collaboration . Working in the same file can be laborious without clear boundaries . As I’ve mentioned previously, Kaggle’s inability to provide branches makes it rather difficult to work on different methods in the same workbook. In addition, having multiple models and preprocessing gets to be a terrifying prospect as your notebook grows and grows alongside your experiments. I ended up commenting out all of my friend’s work in the end so that I could make sure I didn’t accidentally overwrite any of my own or refer to a dependency in the wrong form. . Communicate clearly what libraries you intend to use | Have standardized naming conventions | Make sure you use unique names for models, data sets, training sets, etc. so that you don’t run into broken dependencies | . A system’s ability to do simultaneous version control is an active constraint for group work . I’m not a developer and so I haven’t used Github extensively. I’ve had an account on and off for years, hoping to dive deeper but without collaboration it just didn’t seem to matter. This project opened my eyes to the criticality of version control, branches, and pull requests. I strongly recommend that any collaborative development be done in an environment that allows for those three things (at the least) to ensure you don’t break everything. . Data Science . Experimentation with preprocessing leads to insights about the data . Throughout the work I tried various ways of preprocessing the data to make it fit different models in the documentation. I lokoed across multiple sources and pieced them together to create a few things that were novel to me. Below is one example. I wanted to see if adding in indicator variables for missing data could improve the performance of my models. It didn’t, but it lead to me figuring out how to do some very basic data augmentation, something I know I’ll be exploring more as I continue to learn. . #Here we&#39;ll fill Keywords and Location with &quot;Not Available&quot; to see if this can improve our model. We&#39;ll also add indicator columns for missing data to see if that&#39;s important. def add_indicator(col): def wrapper(df): return df[col].isna().astype(int) return wrapper training_clean = training.assign(kw_miss=add_indicator(&quot;keyword&quot;)) training_clean = training_clean.assign(loc_miss=add_indicator(&quot;location&quot;)) training_clean = training_clean.fillna(&quot;Not Available&quot;) training_clean = training_clean.drop(columns=&quot;target&quot;) . Experimentation from documentation produces limited performance increases . Following some exploration of different architectures within the sklearn documentation I ended up submitting a StackingClassifier to the competition and achieved 82.01% accuracy. This was a marginal improvement over our previous attempts that ranged from 80% to 81.4%. However, the really cool thing I found in doing it was learning more about how to create pipelines that allow for combining different methods of classification to increase performance. I had one pipeline that used a CountVectorizer to preprocess the training data for RandomForestClassifier and SVC classifiers. I also used a TfidfVectorizer that preprocessed the data for MultinomialNB and LogisticGregression classifiers. This allowed me to combine four separate estimators before learning the final classifier on another SVC. While this is an inefficient way to train models, especially as it did not provide significant performance. I found it to be a great opportunity to explore different workflows. . Below is a picture of the Confusion Matrix for the final StackingClassifier that highlights how it performed. Doing this over again I would look deeper into what was causing the false negatives to see if I needed to do data augmentation or select better hyperparameters to improve the model by a larger margin. . . My biggest takeaway regarding Data Science is that experimentation and adjusting hyperparameters are critical parts of developing an accurate model. It feels a bit like trial and error, relying heavily on intuition, and you have to understand how they affect the underlying architecture, individually and in aggregate, to make the most of them. This is part of why I am working my way through the FastAI Course. I want to develop better intuitions and a deeper understanding of the theory underpinning the architectures so I can make better choices. .",
            "url": "https://butterswords.github.io/portfolio/kaggle/nlp/journey/2022/01/17/my-first-real-kaggle-collaboration.html",
            "relUrl": "/kaggle/nlp/journey/2022/01/17/my-first-real-kaggle-collaboration.html",
            "date": " • Jan 17, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hello, my name is Nathan Butters. Feel free to call me “Nathan” or “Butters” as you see fit. Historically, ~50% of everyone I meet calls me “Butters” and I am happy to let you pick what works best for you. . I believe we need to acknowledge our place within the world upfront so that others can interact with the rest of what we offer with awareness of our limitations. So, I focus this page around a statement of positionality (see below). It may work, it may not. . In general, I try to take a little space to acknowledge who I am during conversations, even when it’s difficult or uncomfortable, because it brings into the open implicit power dynamics at play. I’ve never written anything down for public consumption so this stands as a first. Any feedback on it is appreciated. . “Positionality is the notion that personal values, views, and location in time and space influence how one understands the world. In this context, gender, race, class, and other aspects of identities are indicators of social and spatial positions and are not fixed, given qualities. Positions act on the knowledge a person has about things, both material and abstract. Consequently, knowledge is the product of a specific position that reflects particular places and spaces.” - Luis Sánchez, accessed on the Anti-Racist Teaching Collective . What are my known biases (and privileges)? . I am a cis-gender, straight, white man from a middle class family in America. I was raised Catholic. I attended a public charter high school, Illinois Math and Science Academy (IMSA), and private colleges for my undergraduate degree, Illinois Wesleyan University (IWU), and my Master’s, Yale Divinity School (YDS). I have worked for tech giants for the last 5+ years: AWS and Tableau—now part of Salesforce. . I point these things out because they highlight how privileged I am by birth and the choices I’ve made throughout my life. These things have formed who I am and I cannot change them as they are now the historical “facts” of my life. Others may judge me in particular ways based on this information and I will not say they are wrong to do so. . My interests, personality, and values drive me to differentiate myself from many of the attributes described above through self-reflection and interdisciplinary studies. This may seem presumptious to many and I see it as something I will work on the rest of my life. When, or if, I feel I have the words to expand on this I will. . Know that I am open to new ways of thinking and seek out those who provide honest feedback and critiques of my ideas and ways of thinking. . What do I value? . Over the years I have been asked to define my values again and again. For work, for school, for volunteering, for therapy. Each time a few elements keep coming up. I’ve listed them here because I believe they are fundamental to who I am and what I hold true. . Courage | Competence | Compassion | Community | . Non-negotiables for my career . As part of my reflections during the pandemic I realized that I need to operate from a core set of non-negotiables for work so that I know when it’s time to toss in the towel and move on. This came about when I realized that the quote I’d been living by was failing to help me make peace with where I was at: . “Do what you love or make sure what you do supports what you love.” An old man on a beach in Florida in December 2006 . It’s a good piece of advice, flexible and affirming, and most of the time I think it can help you make good decisions about your career. However, when it comes down to it sometimes you need something more concrete to help you know if you’re in the right place. So, I defined these non-negotiables as a way to gauge opportunities that present themselves to me. They are open-ended as well, and demand that I use them in the form of a question to find answers. . Do fulfilling work | Do good for the world | Support my family | . Topics &amp; Issues I care about . I am passionate about many things, too many to list on a page without it becoming a joke. So, I’ve ruthlessly trimmed down to the ones I am most passionate about right now. Some of these have always been true, some have become passions due to life events, some are a product of my biases and positionality. All of them are things I will be happy to discuss for hours with almost anyone. . Indigenous Sovereignty | Data &amp; AI Ethics | Decision Rights | Storytelling | Systems of Power | Human Belief Systems | . My personal leadership philosophy . Support one another with courage and compassion; prioritize the shared good to achieve great success. . Quotes that speak to the core of who I am . “Work smarter, not harder; do not balk at hard work.” - Nathan Butters 1 . “True heroism is remarkably sober, very undramatic. It is not the urge to surpass all others at whatever cost, but the urge to serve others at whatever cost.” ~Arthur Ashe 2 . “Moral courage is the most valuable and usually the most absent characteristic in men.” ~George S. Patton 3 . “Words are pale shadows of forgotten names. As names have power, words have power. Words can light fires in the minds of men. Words can wring tears from the hardest hearts.” ~Patrick Rothfuss, Name of the Wind 4 . On credibility, reliability, competence, and positive descriptors . Ultimately, I don’t like trying to convince people who I am. There’s not much people can say to me that makes me think, “Oh yeah, they are totally reliable… or I can trust they’re competent because they say they are.” If I thought that would work I probably wouldn’t put the energy into creating a space for people to look at my work and discover who I am or how I operate. Instead, I hope that you’ll take the time to get to know me and judge for yourself what descriptors I merit. . . Footnotes . Some additional context: I am aware people misuse the first half of this phrase all the time. Sometimes you’re working as efficiently as possible. Sometimes you don’t have control over your work and the only way to get the job done is to work harder. That’s why both sides of the quote are so important. &#8617; . | Here’s the Wikipedia Article on Arthur Ashe &#8617; . | Here’s the Wikipedia Article on Patton I recognize the person as being problematic, more as I’ve gotten older, yet the quote remains powerful to me as a cornerstone. &#8617; . | Here’s the Wikipedia Article on the book &#8617; . |",
          "url": "https://butterswords.github.io/portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "My Bookshelf",
          "content": "I was not always a reader. Growing up I actually loathed reading. If I could find a way to do something to learn, I would much rather be active than sedentary. I learned to love reading in 6th grade and for decades I read mostly fiction. Recently, as I’ve started to take a greater interest in finding ways to improve the world around me, rather than just survive it, I have returned to reading as a source of continual exploration and growth. . I still prefer to do projects and so a lot of my reading is through audiobooks as I take my kid to school. To help me retain critical points from these books I am committing to writing my thoughts down here. This helps me capture a point-in-time reflection on the book, and perhaps start conversations with others. . Note Where possible I link directly to the publisher for books, or to the wikipedia page. If you would like to read them I recommend checking your local library, supporting a local bookstore, or ordering through the author’s site. . What I am reading . Technology is not Neutral, Stephanie Hare - Audio | Trustworthy Machine Learning, Kush Varshney - Physical, though the link is to his web version for free access | . Highlights of what I have read since 2021 . Sand Talk; How Indigenous Thinking Can Save the World, Tyson Yunkaporta - Audio and Physical | The Age of Surveillance Capitalism, Shoshana Zuboff - Audio and Physical | This is How they Tell Me the World Ends: The Cyberweapons Arms Race, Nicole Perlroth - Audio | Race after Technology: Abolinist Tools for the New Jim Code, Ruha Benjamin - Audio | The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World, Pedro Domingos - Audio and Physical | The Alignment Problem: Machine Learning and Human Values, Brian Christian - Audio | Algorithms of Oppression: How Search Engines Reinforce Racism, Safiya Umoja Noble - Audio | Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, Cathy O’Neil - Audio | The Tyranny of Merit: What’s Become of the Common Good?, Michael J. Sandel - Audio | The Signal and the Noise: Why So Many Predictions Fail - but Some Don’t, Nate Silver - Audio | . What I will read soon . All Too Human, Anne McLaughlin | Data Feminism, Catherine D’Ignazio and Lauren F. Klein | The Costs of Connection, Nick Couldry and Ulises A Mejias | Value Sensitive Design: Shaping Technology with Moral Imagination, Batya Friedman and David G. Henry | Design Justice: Community-Led Practicies to Build the Worlds We Need, Sasha Costanza-Chock | Thinking in Systems, Donella Meadows | . A list of old favorites and cornerstone books I read before 2021 (and likely need to revisit) . Data Visualization and Analytics . Introduction to Probability, Dimitri P. Bertsekas and John N. Tsitsiklis | Now you See it, Stephen Few | Information Dashboard Design, Stephen Few | The Visual Display of Quantitative Information, Edward Tufte I have all of his books. | . | . Religious Studies . Sickness unto Death, Søren Kierkegaard | I and Thou, Martin Buber | Existentialism and Human Emotions, John Paul Sartre | .",
          "url": "https://butterswords.github.io/portfolio/bookshelf/",
          "relUrl": "/bookshelf/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://butterswords.github.io/portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}